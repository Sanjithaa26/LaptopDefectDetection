import os
from PIL import Image
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import torch.optim as optim
from google.colab import drive
drive.mount('/content/drive')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_dir = "/content/drive/MyDrive/Laptop_ds/"
train_img_dir = os.path.join(base_dir, "train", "images")
train_label_dir = os.path.join(base_dir, "train", "labels")
valid_img_dir = os.path.join(base_dir, "valid", "images")
valid_label_dir = os.path.join(base_dir, "valid", "labels")
test_img_dir = os.path.join(base_dir, "test", "images")
test_label_dir = os.path.join(base_dir, "test", "labels")
num_classes = 4


class MultiLabelDataset(Dataset):
    def __init__(self, img_dir, label_dir, transform=None):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.transform = transform
        self.images = sorted(os.listdir(img_dir))

        # Final Class IDs:
        # 0 = crack
        # 1 = lines
        # 2 = defectless
        # 3 = others 
        self.target_class_ids = [0, 2, 3, 'others']  # 'others' placeholder for clarity
        self.class_id_map = {0: 0, 2: 1, 3: 2, 'others': 3}

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.img_dir, img_name)
        label_path = os.path.join(self.label_dir, os.path.splitext(img_name)[0] + ".txt")

        image = Image.open(img_path).convert("RGB")

        label_vec = np.zeros(len(self.target_class_ids), dtype=np.float32)
        if os.path.isfile(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if parts:
                        cid = int(parts[0])

                        # Mapping logic
                        if cid == 1 or cid == 4:
                            label_vec[self.class_id_map['others']] = 1.0
                        elif cid in self.class_id_map:
                            label_vec[self.class_id_map[cid]] = 1.0

        if self.transform:
            image = self.transform(image)

        label_tensor = torch.from_numpy(label_vec)
        return image, label_tensor


transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.RandomAffine(degrees=10, translate=(0.1,0.1), scale=(0.8,1.2)),
    transforms.ColorJitter(0.2,0.2,0.2,0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
])

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
])



batch_size = 16

train_dataset = MultiLabelDataset(train_img_dir, train_label_dir, transform=transform_train)
valid_dataset = MultiLabelDataset(valid_img_dir, valid_label_dir, transform=transform_test)
test_dataset = MultiLabelDataset(test_img_dir, test_label_dir, transform=transform_test)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)



class MultiLabelResNet50(nn.Module):
    def __init__(self, num_classes=num_classes):
        super(MultiLabelResNet50, self).__init__()
        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        in_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Linear(in_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.resnet(x)
model = MultiLabelResNet50().to(device)

# === Loss and optimizer ===
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)

!pip install tqdm
from tqdm import tqdm


import matplotlib.pyplot as plt

train_losses = []
val_losses = []
train_accuracies = []
val_accuracies = []

def multi_label_accuracy(outputs, targets, threshold=0.5):
    preds = (outputs > threshold).float()
    correct = (preds == targets).float().sum()
    total = torch.numel(targets)
    return (correct / total).item()


num_epochs = 25
best_val_loss = float('inf')

for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    train_acc = 0
    train_iter = tqdm(train_loader, desc=f"Train Epoch {epoch+1}")
    for images, labels in train_iter:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_acc += multi_label_accuracy(outputs, labels)
        train_iter.set_postfix(loss=train_loss/(train_iter.n+1), acc=train_acc/(train_iter.n+1))

    train_loss /= len(train_loader)
    train_acc /= len(train_loader)
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)

    model.eval()
    val_loss = 0
    val_acc = 0
    valid_iter = tqdm(valid_loader, desc=f"Valid Epoch {epoch+1}")
    with torch.no_grad():
        for images, labels in valid_iter:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            val_acc += multi_label_accuracy(outputs, labels)
            valid_iter.set_postfix(loss=val_loss/(valid_iter.n+1), acc=val_acc/(valid_iter.n+1))

    val_loss /= len(valid_loader)
    val_acc /= len(valid_loader)
    val_losses.append(val_loss)
    val_accuracies.append(val_acc)

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, "
          f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), os.path.join(base_dir, "best_model_50_4.pth"))
        print("Saved best model")

    scheduler.step()
# Plotting the losses
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train and Validation Loss over Epochs')
plt.legend()
plt.grid(True)
plt.savefig(os.path.join(base_dir, 'loss_plot4.png'))
plt.show()

label_map = {
    0: 'crack',
    1: 'lines',
    2: 'defectless',
    3: 'Others'
}



threshold = 0.5
correct = 0
total = 0

model.load_state_dict(torch.load(os.path.join(base_dir, "best_model_50_4.pth")))
model.eval()

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        preds = (outputs > threshold).float()

        batch_size = labels.size(0)
        total += batch_size

        # Compare predictions with labels
        correct += (preds == labels).all(dim=1).sum().item()

        # For printing predictions
        labels_np = labels.cpu().numpy()
        preds_np = preds.cpu().numpy()

        for i in range(batch_size):
            true_classes = [label_map[idx] for idx, val in enumerate(labels_np[i]) if val == 1]
            pred_classes = [label_map[idx] for idx, val in enumerate(preds_np[i]) if val == 1]

            print(f"True labels: {true_classes}")
            print(f"Predicted labels: {pred_classes}")
            print("---")

print(f"\nTotal images: {total}")
print(f"Correctly predicted images: {correct}")
print(f"Exact match accuracy: {100 * correct / total:.2f}%")














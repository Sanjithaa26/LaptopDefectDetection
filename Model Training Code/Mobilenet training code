import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
from sklearn.metrics import f1_score, accuracy_score
import numpy as np
from google.colab import drive
drive.mount('/content/drive')


class CustomDataset(Dataset):
    def __init__(self, img_dir, label_dir, transform=None, num_classes=4):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.transform = transform
        self.samples = []
        self.num_classes = num_classes

        for img_name in os.listdir(img_dir):
            #if not img_name.endswith(".jpg"):
                #continue
            img_path = os.path.join(img_dir, img_name)
            label_path = os.path.join(label_dir, img_name.replace(".jpg", ".txt"))

            label = torch.zeros(self.num_classes)
            if os.path.exists(label_path):
                with open(label_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if parts and parts[0].isdigit():
                            idx = int(parts[0])
                            if idx == 0:
                                label[0] = 1  # crack
                            elif idx in [1, 4]:
                                label[1] = 1  # others
                            elif idx == 2:
                                label[2] = 1  # lines
                            elif idx == 3:
                                label[3] = 1  # defectless
            self.samples.append((img_path, label))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label


train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])
valid_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


train_img_dir = '/content/drive/MyDrive/Laptop_ds/train/images'
train_label_dir = '/content/drive/MyDrive/Laptop_ds/train/labels'
val_img_dir = '/content/drive/MyDrive/Laptop_ds/valid/images'
val_label_dir = '/content/drive/MyDrive/Laptop_ds/valid/labels'
test_img_dir = '/content/drive/MyDrive/Laptop_ds/test/images'
test_label_dir = '/content/drive/MyDrive/Laptop_ds/test/labels'


num_classes = 4
batch_size = 32

train_dataset = CustomDataset(train_img_dir, train_label_dir, train_transform, num_classes)
val_dataset = CustomDataset(val_img_dir, val_label_dir, valid_transform, num_classes)
test_dataset = CustomDataset(test_img_dir, test_label_dir, valid_transform, num_classes)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)


class CustomMobileNetV2(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.base = models.mobilenet_v2(pretrained=True)
        self.base.classifier[1] = nn.Linear(self.base.last_channel, num_classes)

    def forward(self, x):
        return self.base(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CustomMobileNetV2(num_classes).to(device)


def get_class_weights(dataset):
    total = torch.zeros(num_classes)
    for _, labels in dataset:
        total += labels
    weights = 1 / (total + 1e-6)
    weights = weights / weights.sum() * num_classes
    return weights

class_weights = get_class_weights(train_dataset).to(device)
criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)


num_epochs = 50
best_val_loss = float('inf')
model_path = '/content/drive/MyDrive/Laptop_ds/best_model_final1.pth'
patience = 10
early_stop_counter = 0

for epoch in range(num_epochs):
    model.train()
    total_loss, preds, targets = 0, [], []

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)
        preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())
        targets.extend(labels.cpu().detach().numpy())

    preds_bin = (np.array(preds) > 0.5).astype(int)
    targets = np.array(targets)
    train_f1 = f1_score(targets, preds_bin, average='macro')
    train_acc = accuracy_score(targets, preds_bin)

   
    model.eval()
    val_loss, val_preds, val_targets = 0, [], []
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            val_preds.extend(torch.sigmoid(outputs).cpu().numpy())
            val_targets.extend(labels.cpu().numpy())

    val_preds_bin = (np.array(val_preds) > 0.5).astype(int)
    val_targets = np.array(val_targets)
    val_f1 = f1_score(val_targets, val_preds_bin, average='macro')
    val_acc = accuracy_score(val_targets, val_preds_bin)

    avg_train_loss = total_loss / len(train_dataset)
    avg_val_loss = val_loss / len(val_dataset)

    print(f"Epoch {epoch+1}/{num_epochs} "
          f"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | "
          f"Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}")

    scheduler.step(avg_val_loss)

   
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), model_path)
        print("Best model saved.")
        early_stop_counter = 0
    else:
        early_stop_counter += 1
        print(f"No improvement. Early stopping counter: {early_stop_counter}/{patience}")
        if early_stop_counter >= patience:
            print("Early stopping triggered.")
            break


model.load_state_dict(torch.load(model_path))
model.eval()
test_preds, test_targets = [], []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        test_preds.extend(torch.sigmoid(outputs).cpu().numpy())
        test_targets.extend(labels.cpu().numpy())

test_preds_bin = (np.array(test_preds) > 0.5).astype(int)
test_targets = np.array(test_targets)
test_f1 = f1_score(test_targets, test_preds_bin, average='macro')
test_acc = accuracy_score(test_targets, test_preds_bin)

print(f"\nTest Accuracy: {test_acc:.4f}, Test F1 Score: {test_f1:.4f}")
